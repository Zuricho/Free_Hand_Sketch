{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.utils.data.dataloader as DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# training set\n",
    "data_path_train = 'dataset/train'\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path_train,\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# test set\n",
    "data_path_test = 'dataset/test'\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path_test,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# validation set\n",
    "data_path_valid = 'dataset/valid'\n",
    "valid_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path_valid,\n",
    "    transform=transform\n",
    ")\n",
    "valid_loader = DataLoader.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional neural network\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # FCNN model\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, len(train_dataset.classes))\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.softmax(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to help get prediction\n",
    "def make_prediction(loader, model):\n",
    "    result_total = []\n",
    "    reference_total = []\n",
    "    for index, (data, target) in enumerate(loader):\n",
    "        data, label = data.to(device), torch.eye(len(train_dataset.classes))[target].to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        result = torch.max(output,dim=1).indices.cpu().detach().numpy()\n",
    "        reference = torch.max(label,dim=1).indices.cpu().detach().numpy()\n",
    "\n",
    "        result_total.append(result)\n",
    "        reference_total.append(reference)\n",
    "    return np.hstack(result_total), np.hstack(reference_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85404\\AppData\\Local\\Temp/ipykernel_9616/2019412789.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(self.fc4(x))\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"./model/FCNN_parameter_1.pkl\"))   \n",
    "\n",
    "# validation and test process\n",
    "result_valid, reference_valid = make_prediction(valid_loader, model)\n",
    "result_test, reference_test = make_prediction(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.3461\n",
      "Test accuracy: 0.3449\n",
      "Validation F1 score: 0.2928\n",
      "Test F1 score: 0.2906\n",
      "Validation confusion matrix: \n",
      "[[ 418  193   94   41    8    1   11   92    0  100   11    0   43   97\n",
      "   616  214  159    0    0   61  214   51    5   62    9]\n",
      " [  76 1395  106   34   17    5   11  131    0  162   41    0   13   63\n",
      "    76   14   15    0    0   49  154   36    4   83   15]\n",
      " [  65  196 1077   52   37    7   25   35    0  164   36    0   49   64\n",
      "   212   69   52    0    0   28   35  152   25   82   38]\n",
      " [  12  241   96  354   20   10   27   15    0  279   77    0   60  218\n",
      "    39   50    4    0    0   43  266  126  116   45  402]\n",
      " [  10  174   48   15 1423    7   66   37    0  126   46    0    4   18\n",
      "    20    8   11    0    0   86   27   35   55  252   32]\n",
      " [  64  360   96  103   78   16   87   60    0  205  103    0  136  128\n",
      "   126   59   27    0    0  120  239  269   36  145   43]\n",
      " [  57  164  120   55   35    2  258   88    0  323   23    0  112  246\n",
      "    75   28   38    0    0   71  242  102   12  409   40]\n",
      " [  55  209   23    1    4    0    3 1729    0    6    4    0    0   56\n",
      "   273   10   96    0    0    0    9    8    0   11    3]\n",
      " [  59  395  333    0    0    0    1 1221    0    2   53    0    0   14\n",
      "    48    1  207    0    0    5    1   17    0  138    5]\n",
      " [   4   30   21   12   19    0   12    5    0 2007    1    0   73   26\n",
      "    82   20   13    0    0    5   15    3   21   89   42]\n",
      " [  11  523  209  141   49    9   74   25    0  243  431    0   35   46\n",
      "    40   17   12    0    0   77   92   95   39  214  118]\n",
      " [  76  249  228    3    1    1   14  241    0   26   56    0   17   46\n",
      "   235    5 1011    0    0   17    7   48    1  214    4]\n",
      " [  22   35   31   55   13    1   30    9    0  392   18    0 1199  154\n",
      "   187   80   31    0    0   12   31   56   36   46   62]\n",
      " [  35  117   47   37    6    0   24  104    0  195    7    0  110  694\n",
      "   692  109   92    0    0    7   61   49   33   30   51]\n",
      " [  17   25   41    1    2    0    2   24    0   90    1    0   53   77\n",
      "  1840   99  178    0    0    1    6    9    4   24    6]\n",
      " [  45   19   78   18    2    1    2   12    0  109    1    0   80  132\n",
      "   534 1187  136    0    0    2    9   46   13   12   62]\n",
      " [  14   15   12    0    3    0    0   33    0   31    0    0   22   14\n",
      "   484    3 1823    0    0    0    2    1    1   40    2]\n",
      " [ 155  204  340  119   40    8   30   18    0  162   21    0  161  106\n",
      "   132  316   16    0    0  116  291  132   10   92   31]\n",
      " [  27   82  227   66   91    8   39   20    0  226   47    0  105   95\n",
      "   208  347   25    0    0   54   32  335  199  123  144]\n",
      " [  55  484   61   54   51    6   35   53    0  184   35    0    4   13\n",
      "    34   11   10    0    0  571  514   55    6  257    7]\n",
      " [  72  273   32   50    4    0    9    9    0  360    5    0   53   93\n",
      "    26   32    2    0    0   44 1347   21    6   38   24]\n",
      " [ 155  154  156   56   28    2   33   79    0   47   33    0  111  152\n",
      "   132  182   52    0    0   88  107  800   14   99   20]\n",
      " [   5   66  134  148   80    9   27    5    0  277   53    0  103  114\n",
      "    49  111    6    0    0   24   28  165  512   32  552]\n",
      " [  16  100   81    5   96    1   24   14    0  193   15    0   11    7\n",
      "    41    6   48    0    0  247   51   28    7 1507    2]\n",
      " [   2   85   69  138   13    2   21   12    0  369   98    0   67  239\n",
      "    42   56    2    0    0    6   11   55  160   12 1041]]\n",
      "Test confusion matrix: \n",
      "[[ 438  200   78   50   11    2   12   81    0  114    6    0   28   96\n",
      "   570  207  169    0    0   51  262   44    7   65    9]\n",
      " [  84 1418  111   23   15    1   11  111    0  145   60    0   15   68\n",
      "    64   15    7    0    0   47  164   38    2   88   13]\n",
      " [  71  179 1057   52   38    5   29   46    0  174   48    0   59   56\n",
      "   208   79   54    0    0   21   28  140   18   96   42]\n",
      " [  15  232   94  354   37   11   25   15    0  301   91    0   56  185\n",
      "    37   49    6    0    0   63  261  102  109   29  428]\n",
      " [   4  162   54    6 1453    7   72   39    0  110   43    0    7   22\n",
      "    19    9    8    0    0   97   30   41   53  230   34]\n",
      " [  68  380   90  109   95   23   74   61    0  223   98    0  109  142\n",
      "   103   67   20    0    0  138  215  240   43  144   58]\n",
      " [  65  190  102   61   42    0  251   82    0  297   36    0  120  230\n",
      "    49   24   35    0    0   76  268  126   15  390   41]\n",
      " [  52  183   17    1    1    0    0 1791    0    4    1    0    0   56\n",
      "   270    8   79    0    0    2   14    8    0   11    2]\n",
      " [  55  353  361    0    1    0    1 1244    0    3   47    0    1    6\n",
      "    40    1  194    0    0    6    2   15    0  162    8]\n",
      " [   7   44   22    5   14    0    4    5    0 2002    2    0   64   29\n",
      "    77   20   17    0    0    6   23    4   10  102   43]\n",
      " [  17  542  232  159   50   11   46   34    0  243  381    0   35   40\n",
      "    42   11   12    0    0   88   92  103   42  197  123]\n",
      " [  43  251  226    3    1    0   14  288    0   15   47    0   28   34\n",
      "   276    4 1006    0    0    9   10   57    0  180    8]\n",
      " [  25   30   41   53   22    2   33    7    0  413   11    0 1191  161\n",
      "   178   97   20    0    0   10   33   54   35   39   45]\n",
      " [  41  130   46   54    4    1   22  121    0  222    3    0  115  625\n",
      "   687   91   84    0    0    8   59   67   21   33   66]\n",
      " [  29   24   33    2    2    0    4   20    0   84    0    0   60   83\n",
      "  1855  104  166    0    0    1    0    9    3   13    8]\n",
      " [  45   14   75   21    0    0    2    9    0  112    5    0  107  149\n",
      "   523 1192  120    0    0    0   10   53   13   13   37]\n",
      " [  15   11   11    0    3    0    2   35    0   35    0    0   17   17\n",
      "   483    0 1805    0    0    4    3    1    2   56    0]\n",
      " [ 138  191  347  103   45   13   26   23    0  155   14    0  158  106\n",
      "   161  274   19    0    0  149  295  128   13  117   25]\n",
      " [  26   82  206   62  100    8   32    6    0  233   48    0  114   88\n",
      "   214  327   20    0    0   66   38  303  249  118  160]\n",
      " [  72  528   62   51   39    6   35   42    0  165   39    0   12   19\n",
      "    41   14   12    0    0  537  486   44    9  277   10]\n",
      " [  61  265   21   45   10    1    6   22    0  346    4    0   56   76\n",
      "    25   24    4    0    0   51 1390   24    8   40   21]\n",
      " [ 166  168  148   56   33    7   29   73    0   49   31    0   90  144\n",
      "   152  171   44    0    0   82   98  810   36   92   21]\n",
      " [  13   71  156  161   82   11   23    3    0  278   53    0  107  118\n",
      "    37  110    6    0    0   11   21  214  464   37  524]\n",
      " [  22   93   83    4  105    2   36   15    0  198   11    0    8    4\n",
      "    37    6   35    0    0  224   55   36   11 1511    4]\n",
      " [   0  105   80  140   19    4   26   11    0  336   86    0   48  244\n",
      "    35   60    5    0    0    6   19   62  186   18 1010]]\n",
      "Validation classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.17      0.21      2500\n",
      "           1       0.24      0.56      0.34      2500\n",
      "           2       0.29      0.43      0.34      2500\n",
      "           3       0.23      0.14      0.17      2500\n",
      "           4       0.67      0.57      0.62      2500\n",
      "           5       0.17      0.01      0.01      2500\n",
      "           6       0.30      0.10      0.15      2500\n",
      "           7       0.42      0.69      0.53      2500\n",
      "           8       0.00      0.00      0.00      2500\n",
      "           9       0.32      0.80      0.46      2500\n",
      "          10       0.35      0.17      0.23      2500\n",
      "          11       0.00      0.00      0.00      2500\n",
      "          12       0.46      0.48      0.47      2500\n",
      "          13       0.24      0.28      0.26      2500\n",
      "          14       0.29      0.74      0.42      2500\n",
      "          15       0.39      0.47      0.43      2500\n",
      "          16       0.45      0.73      0.56      2500\n",
      "          17       0.00      0.00      0.00      2500\n",
      "          18       0.00      0.00      0.00      2500\n",
      "          19       0.33      0.23      0.27      2500\n",
      "          20       0.36      0.54      0.43      2500\n",
      "          21       0.30      0.32      0.31      2500\n",
      "          22       0.39      0.20      0.27      2500\n",
      "          23       0.37      0.60      0.46      2500\n",
      "          24       0.38      0.42      0.40      2500\n",
      "\n",
      "    accuracy                           0.35     62500\n",
      "   macro avg       0.29      0.35      0.29     62500\n",
      "weighted avg       0.29      0.35      0.29     62500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.18      0.22      2500\n",
      "           1       0.24      0.57      0.34      2500\n",
      "           2       0.28      0.42      0.34      2500\n",
      "           3       0.22      0.14      0.17      2500\n",
      "           4       0.65      0.58      0.62      2500\n",
      "           5       0.20      0.01      0.02      2500\n",
      "           6       0.31      0.10      0.15      2500\n",
      "           7       0.43      0.72      0.54      2500\n",
      "           8       0.00      0.00      0.00      2500\n",
      "           9       0.32      0.80      0.46      2500\n",
      "          10       0.33      0.15      0.21      2500\n",
      "          11       0.00      0.00      0.00      2500\n",
      "          12       0.46      0.48      0.47      2500\n",
      "          13       0.22      0.25      0.24      2500\n",
      "          14       0.30      0.74      0.43      2500\n",
      "          15       0.40      0.48      0.44      2500\n",
      "          16       0.46      0.72      0.56      2500\n",
      "          17       0.00      0.00      0.00      2500\n",
      "          18       0.00      0.00      0.00      2500\n",
      "          19       0.31      0.21      0.25      2500\n",
      "          20       0.36      0.56      0.44      2500\n",
      "          21       0.30      0.32      0.31      2500\n",
      "          22       0.34      0.19      0.24      2500\n",
      "          23       0.37      0.60      0.46      2500\n",
      "          24       0.37      0.40      0.39      2500\n",
      "\n",
      "    accuracy                           0.34     62500\n",
      "   macro avg       0.29      0.34      0.29     62500\n",
      "weighted avg       0.29      0.34      0.29     62500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "\n",
    "# calculate accuracy and other metrics\n",
    "print('Validation accuracy: %.4f'%accuracy_score(reference_valid, result_valid))\n",
    "print('Test accuracy: %.4f'%accuracy_score(reference_test, result_test))\n",
    "print('Validation F1 score: %.4f'%f1_score(reference_valid, result_valid, average='macro'))\n",
    "print('Test F1 score: %.4f'%f1_score(reference_test, result_test, average='macro'))\n",
    "print('Validation confusion matrix: \\n%s'%confusion_matrix(reference_valid, result_valid))\n",
    "print('Test confusion matrix: \\n%s'%confusion_matrix(reference_test, result_test))\n",
    "print('Validation classification report: \\n%s'%classification_report(reference_valid, result_valid))\n",
    "print('Test classification report: \\n%s'%classification_report(reference_test, result_test))\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Validation confusion matrix epoch %d'%epoch,fontsize=16)\n",
    "confusion_data = confusion_matrix(reference_valid, result_valid)\n",
    "plt.imshow(confusion_data,interpolation='nearest',cmap=\"YlGnBu\",vmax=2500,vmin=0)\n",
    "for i in range(confusion_data.shape[0]):\n",
    "    for j in range(confusion_data.shape[1]):\n",
    "        plt.text(j,i,confusion_data[i,j],ha=\"center\",va=\"center\",fontsize=12)\n",
    "plt.xticks(np.arange(0,confusion_data.shape[1],1),fontsize=12)\n",
    "plt.yticks(np.arange(0,confusion_data.shape[0],1),fontsize=12)\n",
    "plt.savefig('./figure/FCNN_valid_confusion_matrix_epoch_%d.png'%epoch)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Test confusion matrix epoch %d'%epoch,fontsize=16)\n",
    "confusion_data = confusion_matrix(reference_test, result_test)\n",
    "plt.imshow(confusion_data,interpolation='nearest',cmap=\"YlGnBu\",vmax=2500,vmin=0)\n",
    "for i in range(confusion_data.shape[0]):\n",
    "    for j in range(confusion_data.shape[1]):\n",
    "        plt.text(j,i,confusion_data[i,j],ha=\"center\",va=\"center\",fontsize=12)\n",
    "plt.xticks(np.arange(0,confusion_data.shape[1],1),fontsize=12)\n",
    "plt.yticks(np.arange(0,confusion_data.shape[0],1),fontsize=12)\n",
    "plt.savefig('./figure/FCNN_test_confusion_matrix_epoch_%d.png'%epoch)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fb8039a8f54b6eaa53411e1600db4762c5d3778c5768c8cb602a31c798a2c38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
