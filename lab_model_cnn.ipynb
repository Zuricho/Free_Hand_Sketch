{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.utils.data.dataloader as DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# training set\n",
    "data_path_train = 'dataset/train'\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path_train,\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# test set\n",
    "data_path_test = 'dataset/test'\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path_test,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# validation set\n",
    "data_path_valid = 'dataset/valid'\n",
    "valid_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path_valid,\n",
    "    transform=transform\n",
    ")\n",
    "valid_loader = DataLoader.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple neural network\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # CNN model\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, 3)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 3)\n",
    "        self.conv3 = nn.Conv2d(3, 3, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(3*10*10, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, len(train_dataset.classes))\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 3*10*10)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to help get prediction\n",
    "def make_prediction(loader, model):\n",
    "    result_total = []\n",
    "    reference_total = []\n",
    "    for index, (data, target) in enumerate(loader):\n",
    "        data, label = data.to(device), torch.eye(len(train_dataset.classes))[target].to(device)\n",
    "        output = model(data)\n",
    "\n",
    "        result = torch.max(output,dim=1).indices.cpu().detach().numpy()\n",
    "        reference = torch.max(label,dim=1).indices.cpu().detach().numpy()\n",
    "\n",
    "        result_total.append(result)\n",
    "        reference_total.append(reference)\n",
    "    return np.hstack(result_total), np.hstack(reference_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85404\\AppData\\Local\\Temp/ipykernel_8688/1595242939.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(self.fc3(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1750000 (0%)]\tLoss: 3.218938\n",
      "Train Epoch: 1 [10000/1750000 (1%)]\tLoss: 3.214941\n",
      "Train Epoch: 1 [20000/1750000 (1%)]\tLoss: 3.154798\n",
      "Train Epoch: 1 [30000/1750000 (2%)]\tLoss: 3.137721\n",
      "Train Epoch: 1 [40000/1750000 (2%)]\tLoss: 3.113809\n",
      "Train Epoch: 1 [50000/1750000 (3%)]\tLoss: 3.005721\n",
      "Train Epoch: 1 [60000/1750000 (3%)]\tLoss: 3.012617\n",
      "Train Epoch: 1 [70000/1750000 (4%)]\tLoss: 3.020860\n",
      "Train Epoch: 1 [80000/1750000 (5%)]\tLoss: 2.986180\n",
      "Train Epoch: 1 [90000/1750000 (5%)]\tLoss: 2.955538\n",
      "Train Epoch: 1 [100000/1750000 (6%)]\tLoss: 2.994905\n",
      "Train Epoch: 1 [110000/1750000 (6%)]\tLoss: 3.012350\n",
      "Train Epoch: 1 [120000/1750000 (7%)]\tLoss: 2.977234\n",
      "Train Epoch: 1 [130000/1750000 (7%)]\tLoss: 2.998349\n",
      "Train Epoch: 1 [140000/1750000 (8%)]\tLoss: 2.948871\n",
      "Train Epoch: 1 [150000/1750000 (9%)]\tLoss: 2.953561\n",
      "Train Epoch: 1 [160000/1750000 (9%)]\tLoss: 3.015377\n",
      "Train Epoch: 1 [170000/1750000 (10%)]\tLoss: 2.972977\n",
      "Train Epoch: 1 [180000/1750000 (10%)]\tLoss: 2.990863\n",
      "Train Epoch: 1 [190000/1750000 (11%)]\tLoss: 2.971865\n",
      "Train Epoch: 1 [200000/1750000 (11%)]\tLoss: 2.999932\n",
      "Train Epoch: 1 [210000/1750000 (12%)]\tLoss: 2.993384\n",
      "Train Epoch: 1 [220000/1750000 (13%)]\tLoss: 2.958601\n",
      "Train Epoch: 1 [230000/1750000 (13%)]\tLoss: 2.904721\n",
      "Train Epoch: 1 [240000/1750000 (14%)]\tLoss: 3.019717\n",
      "Train Epoch: 1 [250000/1750000 (14%)]\tLoss: 2.880714\n",
      "Train Epoch: 1 [260000/1750000 (15%)]\tLoss: 2.965913\n",
      "Train Epoch: 1 [270000/1750000 (15%)]\tLoss: 3.026151\n",
      "Train Epoch: 1 [280000/1750000 (16%)]\tLoss: 2.934569\n",
      "Train Epoch: 1 [290000/1750000 (17%)]\tLoss: 2.947933\n",
      "Train Epoch: 1 [300000/1750000 (17%)]\tLoss: 2.882433\n",
      "Train Epoch: 1 [310000/1750000 (18%)]\tLoss: 2.898460\n",
      "Train Epoch: 1 [320000/1750000 (18%)]\tLoss: 2.959507\n",
      "Train Epoch: 1 [330000/1750000 (19%)]\tLoss: 2.943495\n",
      "Train Epoch: 1 [340000/1750000 (19%)]\tLoss: 2.978324\n",
      "Train Epoch: 1 [350000/1750000 (20%)]\tLoss: 2.942230\n",
      "Train Epoch: 1 [360000/1750000 (21%)]\tLoss: 2.920500\n",
      "Train Epoch: 1 [370000/1750000 (21%)]\tLoss: 2.868122\n",
      "Train Epoch: 1 [380000/1750000 (22%)]\tLoss: 2.926319\n",
      "Train Epoch: 1 [390000/1750000 (22%)]\tLoss: 2.940585\n",
      "Train Epoch: 1 [400000/1750000 (23%)]\tLoss: 3.000742\n",
      "Train Epoch: 1 [410000/1750000 (23%)]\tLoss: 2.898660\n",
      "Train Epoch: 1 [420000/1750000 (24%)]\tLoss: 2.927506\n",
      "Train Epoch: 1 [430000/1750000 (25%)]\tLoss: 2.928292\n",
      "Train Epoch: 1 [440000/1750000 (25%)]\tLoss: 2.933542\n",
      "Train Epoch: 1 [450000/1750000 (26%)]\tLoss: 2.869350\n",
      "Train Epoch: 1 [460000/1750000 (26%)]\tLoss: 2.984830\n",
      "Train Epoch: 1 [470000/1750000 (27%)]\tLoss: 2.995767\n",
      "Train Epoch: 1 [480000/1750000 (27%)]\tLoss: 2.864661\n",
      "Train Epoch: 1 [490000/1750000 (28%)]\tLoss: 2.866152\n",
      "Train Epoch: 1 [500000/1750000 (29%)]\tLoss: 3.002231\n",
      "Train Epoch: 1 [510000/1750000 (29%)]\tLoss: 2.855932\n",
      "Train Epoch: 1 [520000/1750000 (30%)]\tLoss: 2.929880\n",
      "Train Epoch: 1 [530000/1750000 (30%)]\tLoss: 2.878336\n",
      "Train Epoch: 1 [540000/1750000 (31%)]\tLoss: 2.983948\n",
      "Train Epoch: 1 [550000/1750000 (31%)]\tLoss: 3.014683\n",
      "Train Epoch: 1 [560000/1750000 (32%)]\tLoss: 2.840849\n",
      "Train Epoch: 1 [570000/1750000 (33%)]\tLoss: 2.964108\n",
      "Train Epoch: 1 [580000/1750000 (33%)]\tLoss: 2.862446\n",
      "Train Epoch: 1 [590000/1750000 (34%)]\tLoss: 2.900095\n",
      "Train Epoch: 1 [600000/1750000 (34%)]\tLoss: 2.968057\n",
      "Train Epoch: 1 [610000/1750000 (35%)]\tLoss: 2.930284\n",
      "Train Epoch: 1 [620000/1750000 (35%)]\tLoss: 3.029620\n",
      "Train Epoch: 1 [630000/1750000 (36%)]\tLoss: 2.994659\n",
      "Train Epoch: 1 [640000/1750000 (37%)]\tLoss: 2.862741\n",
      "Train Epoch: 1 [650000/1750000 (37%)]\tLoss: 2.879724\n",
      "Train Epoch: 1 [660000/1750000 (38%)]\tLoss: 2.930371\n",
      "Train Epoch: 1 [670000/1750000 (38%)]\tLoss: 2.961495\n",
      "Train Epoch: 1 [680000/1750000 (39%)]\tLoss: 2.914142\n",
      "Train Epoch: 1 [690000/1750000 (39%)]\tLoss: 2.912774\n",
      "Train Epoch: 1 [700000/1750000 (40%)]\tLoss: 2.969986\n",
      "Train Epoch: 1 [710000/1750000 (41%)]\tLoss: 2.903913\n",
      "Train Epoch: 1 [720000/1750000 (41%)]\tLoss: 2.858935\n",
      "Train Epoch: 1 [730000/1750000 (42%)]\tLoss: 2.886842\n",
      "Train Epoch: 1 [740000/1750000 (42%)]\tLoss: 2.919112\n",
      "Train Epoch: 1 [750000/1750000 (43%)]\tLoss: 2.921865\n",
      "Train Epoch: 1 [760000/1750000 (43%)]\tLoss: 2.856007\n",
      "Train Epoch: 1 [770000/1750000 (44%)]\tLoss: 2.870572\n",
      "Train Epoch: 1 [780000/1750000 (45%)]\tLoss: 2.944630\n",
      "Train Epoch: 1 [790000/1750000 (45%)]\tLoss: 2.910482\n",
      "Train Epoch: 1 [800000/1750000 (46%)]\tLoss: 2.919781\n",
      "Train Epoch: 1 [810000/1750000 (46%)]\tLoss: 2.888034\n",
      "Train Epoch: 1 [820000/1750000 (47%)]\tLoss: 2.911039\n",
      "Train Epoch: 1 [830000/1750000 (47%)]\tLoss: 2.866015\n",
      "Train Epoch: 1 [840000/1750000 (48%)]\tLoss: 2.966603\n",
      "Train Epoch: 1 [850000/1750000 (49%)]\tLoss: 2.947600\n",
      "Train Epoch: 1 [860000/1750000 (49%)]\tLoss: 2.917619\n",
      "Train Epoch: 1 [870000/1750000 (50%)]\tLoss: 2.917624\n",
      "Train Epoch: 1 [880000/1750000 (50%)]\tLoss: 2.875261\n",
      "Train Epoch: 1 [890000/1750000 (51%)]\tLoss: 2.865652\n",
      "Train Epoch: 1 [900000/1750000 (51%)]\tLoss: 2.874355\n",
      "Train Epoch: 1 [910000/1750000 (52%)]\tLoss: 2.951658\n",
      "Train Epoch: 1 [920000/1750000 (53%)]\tLoss: 2.876187\n",
      "Train Epoch: 1 [930000/1750000 (53%)]\tLoss: 2.920524\n",
      "Train Epoch: 1 [940000/1750000 (54%)]\tLoss: 2.881096\n",
      "Train Epoch: 1 [950000/1750000 (54%)]\tLoss: 2.919364\n",
      "Train Epoch: 1 [960000/1750000 (55%)]\tLoss: 2.875107\n",
      "Train Epoch: 1 [970000/1750000 (55%)]\tLoss: 2.872068\n",
      "Train Epoch: 1 [980000/1750000 (56%)]\tLoss: 2.914054\n",
      "Train Epoch: 1 [990000/1750000 (57%)]\tLoss: 2.847291\n",
      "Train Epoch: 1 [1000000/1750000 (57%)]\tLoss: 2.846471\n",
      "Train Epoch: 1 [1010000/1750000 (58%)]\tLoss: 2.894140\n",
      "Train Epoch: 1 [1020000/1750000 (58%)]\tLoss: 2.821201\n",
      "Train Epoch: 1 [1030000/1750000 (59%)]\tLoss: 2.835970\n",
      "Train Epoch: 1 [1040000/1750000 (59%)]\tLoss: 2.833499\n",
      "Train Epoch: 1 [1050000/1750000 (60%)]\tLoss: 2.904323\n",
      "Train Epoch: 1 [1060000/1750000 (61%)]\tLoss: 2.832560\n",
      "Train Epoch: 1 [1070000/1750000 (61%)]\tLoss: 2.776271\n",
      "Train Epoch: 1 [1080000/1750000 (62%)]\tLoss: 2.891227\n",
      "Train Epoch: 1 [1090000/1750000 (62%)]\tLoss: 2.863019\n",
      "Train Epoch: 1 [1100000/1750000 (63%)]\tLoss: 2.873763\n",
      "Train Epoch: 1 [1110000/1750000 (63%)]\tLoss: 2.855485\n",
      "Train Epoch: 1 [1120000/1750000 (64%)]\tLoss: 2.848819\n",
      "Train Epoch: 1 [1130000/1750000 (65%)]\tLoss: 2.919372\n",
      "Train Epoch: 1 [1140000/1750000 (65%)]\tLoss: 2.809169\n",
      "Train Epoch: 1 [1150000/1750000 (66%)]\tLoss: 2.828171\n",
      "Train Epoch: 1 [1160000/1750000 (66%)]\tLoss: 2.812460\n",
      "Train Epoch: 1 [1170000/1750000 (67%)]\tLoss: 2.814083\n",
      "Train Epoch: 1 [1180000/1750000 (67%)]\tLoss: 2.887823\n",
      "Train Epoch: 1 [1190000/1750000 (68%)]\tLoss: 2.918213\n",
      "Train Epoch: 1 [1200000/1750000 (69%)]\tLoss: 2.828624\n",
      "Train Epoch: 1 [1210000/1750000 (69%)]\tLoss: 2.796802\n",
      "Train Epoch: 1 [1220000/1750000 (70%)]\tLoss: 2.866272\n",
      "Train Epoch: 1 [1230000/1750000 (70%)]\tLoss: 2.867206\n",
      "Train Epoch: 1 [1240000/1750000 (71%)]\tLoss: 2.851495\n",
      "Train Epoch: 1 [1250000/1750000 (71%)]\tLoss: 2.802387\n",
      "Train Epoch: 1 [1260000/1750000 (72%)]\tLoss: 2.880723\n",
      "Train Epoch: 1 [1270000/1750000 (73%)]\tLoss: 2.922199\n",
      "Train Epoch: 1 [1280000/1750000 (73%)]\tLoss: 2.952501\n",
      "Train Epoch: 1 [1290000/1750000 (74%)]\tLoss: 2.839629\n",
      "Train Epoch: 1 [1300000/1750000 (74%)]\tLoss: 2.822358\n",
      "Train Epoch: 1 [1310000/1750000 (75%)]\tLoss: 2.847313\n",
      "Train Epoch: 1 [1320000/1750000 (75%)]\tLoss: 2.851840\n",
      "Train Epoch: 1 [1330000/1750000 (76%)]\tLoss: 2.862914\n",
      "Train Epoch: 1 [1340000/1750000 (77%)]\tLoss: 2.831815\n",
      "Train Epoch: 1 [1350000/1750000 (77%)]\tLoss: 2.802531\n",
      "Train Epoch: 1 [1360000/1750000 (78%)]\tLoss: 2.904949\n",
      "Train Epoch: 1 [1370000/1750000 (78%)]\tLoss: 2.805572\n",
      "Train Epoch: 1 [1380000/1750000 (79%)]\tLoss: 2.817958\n",
      "Train Epoch: 1 [1390000/1750000 (79%)]\tLoss: 2.805599\n",
      "Train Epoch: 1 [1400000/1750000 (80%)]\tLoss: 2.832977\n",
      "Train Epoch: 1 [1410000/1750000 (81%)]\tLoss: 2.915321\n",
      "Train Epoch: 1 [1420000/1750000 (81%)]\tLoss: 2.900466\n",
      "Train Epoch: 1 [1430000/1750000 (82%)]\tLoss: 2.750331\n",
      "Train Epoch: 1 [1440000/1750000 (82%)]\tLoss: 2.826354\n",
      "Train Epoch: 1 [1450000/1750000 (83%)]\tLoss: 2.827150\n",
      "Train Epoch: 1 [1460000/1750000 (83%)]\tLoss: 2.796947\n",
      "Train Epoch: 1 [1470000/1750000 (84%)]\tLoss: 2.824099\n",
      "Train Epoch: 1 [1480000/1750000 (85%)]\tLoss: 2.843901\n",
      "Train Epoch: 1 [1490000/1750000 (85%)]\tLoss: 2.726713\n",
      "Train Epoch: 1 [1500000/1750000 (86%)]\tLoss: 2.846932\n",
      "Train Epoch: 1 [1510000/1750000 (86%)]\tLoss: 2.850892\n",
      "Train Epoch: 1 [1520000/1750000 (87%)]\tLoss: 2.845376\n",
      "Train Epoch: 1 [1530000/1750000 (87%)]\tLoss: 2.808369\n",
      "Train Epoch: 1 [1540000/1750000 (88%)]\tLoss: 2.770482\n",
      "Train Epoch: 1 [1550000/1750000 (89%)]\tLoss: 2.775351\n",
      "Train Epoch: 1 [1560000/1750000 (89%)]\tLoss: 2.734953\n",
      "Train Epoch: 1 [1570000/1750000 (90%)]\tLoss: 2.784869\n",
      "Train Epoch: 1 [1580000/1750000 (90%)]\tLoss: 2.724349\n",
      "Train Epoch: 1 [1590000/1750000 (91%)]\tLoss: 2.784539\n",
      "Train Epoch: 1 [1600000/1750000 (91%)]\tLoss: 2.758724\n",
      "Train Epoch: 1 [1610000/1750000 (92%)]\tLoss: 2.749722\n",
      "Train Epoch: 1 [1620000/1750000 (93%)]\tLoss: 2.743704\n",
      "Train Epoch: 1 [1630000/1750000 (93%)]\tLoss: 2.831595\n",
      "Train Epoch: 1 [1640000/1750000 (94%)]\tLoss: 2.882855\n",
      "Train Epoch: 1 [1650000/1750000 (94%)]\tLoss: 2.771032\n",
      "Train Epoch: 1 [1660000/1750000 (95%)]\tLoss: 2.709397\n",
      "Train Epoch: 1 [1670000/1750000 (95%)]\tLoss: 2.786062\n",
      "Train Epoch: 1 [1680000/1750000 (96%)]\tLoss: 2.791785\n",
      "Train Epoch: 1 [1690000/1750000 (97%)]\tLoss: 2.821311\n",
      "Train Epoch: 1 [1700000/1750000 (97%)]\tLoss: 2.757792\n",
      "Train Epoch: 1 [1710000/1750000 (98%)]\tLoss: 2.860229\n",
      "Train Epoch: 1 [1720000/1750000 (98%)]\tLoss: 2.803631\n",
      "Train Epoch: 1 [1730000/1750000 (99%)]\tLoss: 2.959207\n",
      "Train Epoch: 1 [1740000/1750000 (99%)]\tLoss: 2.851696\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8688/2434969092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# validation and test process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mresult_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mresult_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8688/4119200180.py\u001b[0m in \u001b[0;36mmake_prediction\u001b[1;34m(loader, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mreference_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.0005 # learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "epoch_num = 1   \n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(1,epoch_num+1):\n",
    "    # training process\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, label = data.to(device), torch.eye(len(train_dataset.classes))[target].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    # calculate accuracy and other metrics\n",
    "    torch.save(model.state_dict(), \"./model/CNN_parameter_%d.pkl\"%epoch)\n",
    "\n",
    "    # plot the loss figure\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(loss_list,linewidth=1)\n",
    "    plt.xlim(0,epoch*len(train_loader))\n",
    "    plt.xlabel('epoch',fontsize=14)\n",
    "    plt.ylabel('loss',fontsize=14)\n",
    "    plt.xticks(np.arange(0,epoch*len(train_loader)+1,len(train_loader)),np.arange(0,epoch+1,1),fontsize=12)\n",
    "    plt.savefig('./figure/CNN_loss_epoch_%d.png'%epoch)\n",
    "    plt.close()\n",
    "\n",
    "    # validation and test process\n",
    "    result_valid, reference_valid = make_prediction(valid_loader, model)\n",
    "    result_test, reference_test = make_prediction(test_loader, model)\n",
    "\n",
    "    # calculate accuracy and other metrics\n",
    "    print('Validation accuracy: %.4f'%accuracy_score(reference_valid, result_valid))\n",
    "    print('Test accuracy: %.4f'%accuracy_score(reference_test, result_test))\n",
    "    print('Validation F1 score: %.4f'%f1_score(reference_valid, result_valid, average='macro'))\n",
    "    print('Test F1 score: %.4f'%f1_score(reference_test, result_test, average='macro'))\n",
    "    print('Validation confusion matrix: \\n%s'%confusion_matrix(reference_valid, result_valid))\n",
    "    print('Test confusion matrix: \\n%s'%confusion_matrix(reference_test, result_test))\n",
    "    print('Validation classification report: \\n%s'%classification_report(reference_valid, result_valid))\n",
    "    print('Test classification report: \\n%s'%classification_report(reference_test, result_test))\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.title('Validation confusion matrix epoch %d'%epoch,fontsize=16)\n",
    "    confusion_data = confusion_matrix(reference_valid, result_valid)\n",
    "    plt.imshow(confusion_data,interpolation='nearest',cmap=\"YlGnBu\",vmax=2500,vmin=0)\n",
    "    for i in range(confusion_data.shape[0]):\n",
    "        for j in range(confusion_data.shape[1]):\n",
    "            plt.text(j,i,confusion_data[i,j],ha=\"center\",va=\"center\",fontsize=12)\n",
    "    plt.xticks(np.arange(0,confusion_data.shape[1],1),fontsize=12)\n",
    "    plt.yticks(np.arange(0,confusion_data.shape[0],1),fontsize=12)\n",
    "    plt.savefig('./figure/CNN_valid_confusion_matrix_epoch_%d.png'%epoch)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.title('Test confusion matrix epoch %d'%epoch,fontsize=16)\n",
    "    confusion_data = confusion_matrix(reference_test, result_test)\n",
    "    plt.imshow(confusion_data,interpolation='nearest',cmap=\"YlGnBu\",vmax=2500,vmin=0)\n",
    "    for i in range(confusion_data.shape[0]):\n",
    "        for j in range(confusion_data.shape[1]):\n",
    "            plt.text(j,i,confusion_data[i,j],ha=\"center\",va=\"center\",fontsize=12)\n",
    "    plt.xticks(np.arange(0,confusion_data.shape[1],1),fontsize=12)\n",
    "    plt.yticks(np.arange(0,confusion_data.shape[0],1),fontsize=12)\n",
    "    plt.savefig('./figure/CNN_test_confusion_matrix_epoch_%d.png'%epoch)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85404\\AppData\\Local\\Temp/ipykernel_8688/1595242939.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(self.fc3(x))\n"
     ]
    }
   ],
   "source": [
    "result_valid, reference_valid = make_prediction(valid_loader, model)\n",
    "result_test, reference_test = make_prediction(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_model = CNN().to(device)\n",
    "# new_model.load_state_dict(torch.load(\"./model/CNN_parameter.pkl\"))   \n",
    "# new_model.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.4634\n",
      "Test accuracy: 0.4616\n",
      "Validation F1 score: 0.3855\n",
      "Test F1 score: 0.3846\n",
      "Validation confusion matrix: \n",
      "[[ 669  127    0    0   52    0    0   46    1    0   51   68    0  233\n",
      "   145  456  117    0    0  270  125   34   30   67    9]\n",
      " [   9 2152    0    0   13    0    0   18   29    0   41    5    0   11\n",
      "     2    8    4    0    0   62   20   33   36   24   33]\n",
      " [ 390  200    0    0  140    0    0   10    8    0   71   65    0  340\n",
      "   115  407   15    0    0  123   32   99  185  284   16]\n",
      " [   7  220    0    0   72    0    0   15    8    0  379   11    0   62\n",
      "     2   55    3    0    0  328  212   18  630   16  462]\n",
      " [   4   11    0    0 2186    0    0   11    2    0    7   12    0   15\n",
      "     4   24    3    0    0   72    9   10   50   76    4]\n",
      " [ 128  307    0    0  185    0    0   27   21    0  322   37    0  205\n",
      "   105  159   11    0    0  384  121  142  193   87   66]\n",
      " [  34  333    0    0  103    0    0    9    2    0  197   35    0  361\n",
      "    26   67   26    0    0  555  160  141  259   75  117]\n",
      " [  11   94    0    0   28    0    0 1986  122    0   14   54    0   65\n",
      "     8    6   22    0    0   23    9   24    6   24    4]\n",
      " [   1  108    0    0    4    0    0  100 2126    0   45   67    0    5\n",
      "     1    0    9    0    0   10    0    4    1    4   15]\n",
      " [   6  350    0    0   68    0    0    1    2    0    7    7    0  164\n",
      "    26  285    9    0    0   54  157   28  737  412  187]\n",
      " [   3  268    0    0   75    0    0   14   54    0 1505   13    0   13\n",
      "     3   16    2    0    0  184   30   15  120   33  152]\n",
      " [  24   68    0    0   13    0    0   75  135    0    9 1608    0   93\n",
      "    45   38  177    0    0   20    5  136   14   26   14]\n",
      " [ 305   23    0    0   67    0    0    2    0    0   26   20    0  482\n",
      "   147  664   42    0    0   58  129   76  325  101   33]\n",
      " [  86   90    0    0   30    0    0   61    1    0    7   96    0 1246\n",
      "    81  319   37    0    0   18   29  101  192   59   47]\n",
      " [  47   34    0    0   10    0    0    9    0    0    4   39    0  166\n",
      "  1500  391  209    0    0    2    8   16   26   16   23]\n",
      " [  90   16    0    0   15    0    0    3    0    0    2   31    0  104\n",
      "    96 1944   43    0    0    5    7   24   71   34   15]\n",
      " [  15   27    0    0    5    0    0   22    4    0    3  121    0   81\n",
      "   171   35 1952    0    0    1    6   26    6   15   10]\n",
      " [ 636  119    0    0  109    0    0    6    5    0   82    8    0  138\n",
      "    83  458    6    0    0  282  215  115  131   93   14]\n",
      " [  62   54    0    0  219    0    0    4    4    0   32   33    0  182\n",
      "    31  736    4    0    0   86   22  232  573  182   44]\n",
      " [  14  146    0    0  145    0    0   20   11    0   68   17    0   53\n",
      "    10   21    3    0    0 1667   96   17   42  162    8]\n",
      " [  26  199    0    0   34    0    0   16    3    0   42    4    0   35\n",
      "     1   30    0    0    0  233 1653   31   93   49   51]\n",
      " [   9  123    0    0   59    0    0   13   11    0   14   59    0   87\n",
      "    11   60   20    0    0   24   17 1760  152   43   38]\n",
      " [  34   73    0    0  103    0    0    1    3    0   59   11    0   86\n",
      "     5  196    3    0    0   61   26   46 1325   37  431]\n",
      " [  11   26    0    0  241    0    0    5    6    0    7   16    0   17\n",
      "     2   26    4    0    0   88   14   30   17 1984    6]\n",
      " [   0   89    0    0   20    0    0    2   10    0  117    8    0   15\n",
      "     3   11    1    0    0   11    8   29  472    3 1701]]\n",
      "Test confusion matrix: \n",
      "[[ 645  109    0    0   44    0    0   49    3    0   57   55    0  226\n",
      "   149  447  140    0    0  267  135   47   38   74   15]\n",
      " [   8 2177    0    0   13    0    0   12   34    0   48    6    0    4\n",
      "     1    7    1    0    0   40   23   22   32   29   43]\n",
      " [ 445  183    0    0  137    0    0   10    9    0   63   47    0  326\n",
      "   100  376   22    0    0  135   48   87  167  328   17]\n",
      " [  12  198    0    0   62    0    0   10    8    0  344   12    0   54\n",
      "     3   66    1    0    0  321  214   25  674   15  481]\n",
      " [   3   23    0    0 2166    0    0    7    1    0    9   18    0   12\n",
      "     1   24    4    0    0   65   10    4   52   94    7]\n",
      " [ 111  321    0    0  191    0    0   18   22    0  338   24    0  211\n",
      "    90  126   19    0    0  415  127  117  231   81   58]\n",
      " [  40  361    0    0   93    0    0    8    1    0  175   26    0  359\n",
      "    17   61   24    0    0  548  172  163  272   67  113]\n",
      " [  19   96    0    0   19    0    0 2056  107    0   13   53    0   55\n",
      "     5    3   12    0    0   24    3   20    1    9    5]\n",
      " [   1  107    0    0    2    0    0   98 2109    0   40   69    0    6\n",
      "     5    1   11    0    0   14    0    3    4    7   23]\n",
      " [   8  361    0    0   70    0    0    1    1    0   13    9    0  161\n",
      "    25  286    5    0    0   58  193   22  661  433  193]\n",
      " [   4  259    0    0   77    0    0   10   44    0 1510    7    0   20\n",
      "     5   16    5    0    0  186   29   15  116   44  153]\n",
      " [  16   63    0    0   14    0    0   83  152    0    9 1633    0   98\n",
      "    24   47  194    0    0   11    6  100   15   23   12]\n",
      " [ 296   29    0    0   62    0    0    3    0    0   21    9    0  503\n",
      "   127  687   48    0    0   46  140   96  322   78   33]\n",
      " [  97   93    0    0   26    0    0   50    1    0    0   93    0 1245\n",
      "   104  314   33    0    0   25   19  110  186   50   54]\n",
      " [  55   38    0    0   10    0    0    8    0    0    5   29    0  174\n",
      "  1511  382  196    0    0    3    3   16   27   20   23]\n",
      " [  89   12    0    0   21    0    0    6    1    0    4   17    0  146\n",
      "    99 1920   38    0    0    7    8   25   63   23   21]\n",
      " [  20   29    0    0    4    0    0   11    0    0    6  119    0   60\n",
      "   179   44 1965    0    0    2    6   20    5    8   22]\n",
      " [ 632  123    0    0  130    0    0    6    3    0   79    9    0  150\n",
      "    92  420    2    0    0  294  218   85  123  116   18]\n",
      " [  62   51    0    0  219    0    0   10    6    0   33   47    0  142\n",
      "    35  696    3    0    0   84   24  229  593  201   65]\n",
      " [  25  166    0    0  135    0    0   19    6    0   94   19    0   52\n",
      "     5   34    0    0    0 1640   73   15   54  150   13]\n",
      " [  30  204    0    0   42    0    0   16    0    0   25    6    0   41\n",
      "     2   34    1    0    0  250 1629   16  101   45   58]\n",
      " [   7  128    0    0   65    0    0   11   10    0   12   64    0   76\n",
      "    21   58   20    0    0   20   11 1724  157   54   62]\n",
      " [  29   72    0    0  105    0    0    0    2    0   70    7    0   79\n",
      "     6  224    0    0    0   65   27   62 1283   42  427]\n",
      " [  13   30    0    0  231    0    0    4    4    0    7   24    0   24\n",
      "     3   43    3    0    0   79   13   31   13 1975    3]\n",
      " [   0   82    0    0   21    0    0    2    8    0  104    8    0   15\n",
      "     1   16    1    0    0   15    8   21  532    4 1662]]\n",
      "Validation classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.27      0.26      2500\n",
      "           1       0.41      0.86      0.55      2500\n",
      "           2       0.00      0.00      0.00      2500\n",
      "           3       0.00      0.00      0.00      2500\n",
      "           4       0.55      0.87      0.67      2500\n",
      "           5       0.00      0.00      0.00      2500\n",
      "           6       0.00      0.00      0.00      2500\n",
      "           7       0.80      0.79      0.80      2500\n",
      "           8       0.83      0.85      0.84      2500\n",
      "           9       0.00      0.00      0.00      2500\n",
      "          10       0.48      0.60      0.54      2500\n",
      "          11       0.66      0.64      0.65      2500\n",
      "          12       0.00      0.00      0.00      2500\n",
      "          13       0.29      0.50      0.37      2500\n",
      "          14       0.57      0.60      0.59      2500\n",
      "          15       0.30      0.78      0.44      2500\n",
      "          16       0.72      0.78      0.75      2500\n",
      "          17       0.00      0.00      0.00      2500\n",
      "          18       0.00      0.00      0.00      2500\n",
      "          19       0.36      0.67      0.47      2500\n",
      "          20       0.53      0.66      0.59      2500\n",
      "          21       0.55      0.70      0.62      2500\n",
      "          22       0.23      0.53      0.32      2500\n",
      "          23       0.51      0.79      0.62      2500\n",
      "          24       0.49      0.68      0.57      2500\n",
      "\n",
      "    accuracy                           0.46     62500\n",
      "   macro avg       0.34      0.46      0.39     62500\n",
      "weighted avg       0.34      0.46      0.39     62500\n",
      "\n",
      "Test classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.26      0.25      2500\n",
      "           1       0.41      0.87      0.56      2500\n",
      "           2       0.00      0.00      0.00      2500\n",
      "           3       0.00      0.00      0.00      2500\n",
      "           4       0.55      0.87      0.67      2500\n",
      "           5       0.00      0.00      0.00      2500\n",
      "           6       0.00      0.00      0.00      2500\n",
      "           7       0.82      0.82      0.82      2500\n",
      "           8       0.83      0.84      0.84      2500\n",
      "           9       0.00      0.00      0.00      2500\n",
      "          10       0.49      0.60      0.54      2500\n",
      "          11       0.68      0.65      0.67      2500\n",
      "          12       0.00      0.00      0.00      2500\n",
      "          13       0.29      0.50      0.37      2500\n",
      "          14       0.58      0.60      0.59      2500\n",
      "          15       0.30      0.77      0.43      2500\n",
      "          16       0.72      0.79      0.75      2500\n",
      "          17       0.00      0.00      0.00      2500\n",
      "          18       0.00      0.00      0.00      2500\n",
      "          19       0.36      0.66      0.46      2500\n",
      "          20       0.52      0.65      0.58      2500\n",
      "          21       0.56      0.69      0.62      2500\n",
      "          22       0.22      0.51      0.31      2500\n",
      "          23       0.50      0.79      0.61      2500\n",
      "          24       0.46      0.66      0.55      2500\n",
      "\n",
      "    accuracy                           0.46     62500\n",
      "   macro avg       0.34      0.46      0.38     62500\n",
      "weighted avg       0.34      0.46      0.38     62500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Anaconda3\\envs\\torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Validation accuracy: %.4f'%accuracy_score(reference_valid, result_valid))\n",
    "print('Test accuracy: %.4f'%accuracy_score(reference_test, result_test))\n",
    "print('Validation F1 score: %.4f'%f1_score(reference_valid, result_valid, average='macro'))\n",
    "print('Test F1 score: %.4f'%f1_score(reference_test, result_test, average='macro'))\n",
    "print('Validation confusion matrix: \\n%s'%confusion_matrix(reference_valid, result_valid))\n",
    "print('Test confusion matrix: \\n%s'%confusion_matrix(reference_test, result_test))\n",
    "print('Validation classification report: \\n%s'%classification_report(reference_valid, result_valid))\n",
    "print('Test classification report: \\n%s'%classification_report(reference_test, result_test))\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Validation confusion matrix epoch %d'%epoch,fontsize=16)\n",
    "confusion_data = confusion_matrix(reference_valid, result_valid)\n",
    "plt.imshow(confusion_data,interpolation='nearest',cmap=\"YlGnBu\",vmax=2500,vmin=0)\n",
    "for i in range(confusion_data.shape[0]):\n",
    "    for j in range(confusion_data.shape[1]):\n",
    "        plt.text(j,i,confusion_data[i,j],ha=\"center\",va=\"center\",fontsize=12)\n",
    "plt.xticks(np.arange(0,confusion_data.shape[1],1),fontsize=12)\n",
    "plt.yticks(np.arange(0,confusion_data.shape[0],1),fontsize=12)\n",
    "plt.savefig('./figure/CNN_valid_confusion_matrix_epoch_%d.png'%epoch)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Test confusion matrix epoch %d'%epoch,fontsize=16)\n",
    "confusion_data = confusion_matrix(reference_test, result_test)\n",
    "plt.imshow(confusion_data,interpolation='nearest',cmap=\"YlGnBu\",vmax=2500,vmin=0)\n",
    "for i in range(confusion_data.shape[0]):\n",
    "    for j in range(confusion_data.shape[1]):\n",
    "        plt.text(j,i,confusion_data[i,j],ha=\"center\",va=\"center\",fontsize=12)\n",
    "plt.xticks(np.arange(0,confusion_data.shape[1],1),fontsize=12)\n",
    "plt.yticks(np.arange(0,confusion_data.shape[0],1),fontsize=12)\n",
    "plt.savefig('./figure/CNN_test_confusion_matrix_epoch_%d.png'%epoch)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fb8039a8f54b6eaa53411e1600db4762c5d3778c5768c8cb602a31c798a2c38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
